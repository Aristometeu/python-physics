{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random numbers\n",
    "\n",
    "In this notebook we start using Python as a tool for scientific investigation. The topic of random numbers will be our first endeavor and there are good reasons we chose to do it this way. As we shall see, the machinery of basic statistics, which relies heavily on sampling and storing data, will demand from us intensive use of the data structures we have studied so far. Furthermore, random phenomena are perhaps the best example of scientific problems that are better solved with a computer than by hand. It is famously recounted that [Stanislaw Ulam](https://en.wikipedia.org/wiki/Stanislaw_Ulam), after hours trying to compute with combinatorics the chances of winning a [Solitaire](https://en.wikipedia.org/wiki/Canfield_(solitaire) match, reasoned that there had to be an easier way to come up with the right answer by sheer experimentation. The basic ideia is: play a million Solitaire matches and you will likely have a decent approximation. Thus was born the modern [Monte Carlo method](https://en.wikipedia.org/wiki/Monte_Carlo_method). \n",
    "If you skim the wikipedia page on Monte Carlo, you will probably see that even before Ulam, in the 18th century, the [Comte de Buffon](https://en.wikipedia.org/wiki/Georges-Louis_Leclerc,_Comte_de_Buffon) was already playing similar games. The rules to these games are dictated by statistics. We shall use Python to make sense of them. \n",
    "\n",
    "From this point on, we will choose the numpy library for our numerics. Many of the things we shall do here could be done with the random or math modules. Nevertheless, the numpy module has been developed and optimized for scientific computing and includes several data types that behave like scientists would think they should. Let us import numpy as np and look at our first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us investigate some concepts in probability theory. We start with the Bernoulli distribution.\n",
    "### The Bernoulli distribution\n",
    "\n",
    "Let the random variable $X$ take on the values $X = 1$ with probability p and $X = 0$ with probability $1-p$, where evidently $0 \\leq p \\leq 1 $. Such variable is said to have a [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution) and we write $ X \\sim \\text{Bernoulli}(p) $. The variable $X$ could represent, for example, a coin flip. Under a frequentist interpretation of probability, we expect that after a large number n of trials, the proportion of 1's approaches p and the proportion of 0's approaches 1-p. Let's check that with Python.\n",
    "\n",
    "```python\n",
    "def bernoulli(p):\n",
    "    coinFlip = np.random.uniform() \n",
    "    if coinFlip < p:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def toss_coin(n = 10000, p = 0.5):\n",
    "    n = 10000\n",
    "    p = 0.60\n",
    "    heads = 0\n",
    "    tails = 0\n",
    "    for trials in range(n):\n",
    "        if bernoulli(p) == 1:\n",
    "            heads += 1\n",
    "        else:\n",
    "            tails  += 1\n",
    "    print(\"Proportion of heads: \", heads/n)\n",
    "    print(\"Proportion of tails: \", tails/n)\n",
    "\n",
    "``` \n",
    "Run the code above with different values of p and N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of heads: 0.495100\n"
     ]
    }
   ],
   "source": [
    "def bernoulli(p):\n",
    "    coinFlip = np.random.uniform() \n",
    "    if coinFlip < p:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def toss_coin(n = 10000, p = 0.5):\n",
    "    n = n\n",
    "    p = p\n",
    "    heads = 0\n",
    "    tails = 0\n",
    "    for trials in range(n):\n",
    "        if bernoulli(p) == 1:\n",
    "            heads += 1\n",
    "    pHeads = heads/n\n",
    "    return pHeads\n",
    "\n",
    "print(\"Proportion of heads: %f\" %toss_coin())\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.  The Binomial distribution. \n",
    "Suppose the random variable $X$ described above is a coin. Let $p$ be the probability of it landing heads. We toss this coin $n$ times and get $z$ heads. We are assuming that each toss is an independent sample of the Bernoulli distribution. Now let $f(m) = P(M = m)$ be the probability that we get exactly $m$ heads after $n$ trials. Then for $0 \\leq m \\leq n$ we have\n",
    "\\begin{equation}\n",
    "f(m) = \\binom{n}{m}p^m(1-p)^{(n-m)}\n",
    "\\end{equation}\n",
    "Clearly, $f(m) = 0$ if $m < 0$ or $m > n$. The random variable $M$ is distributed according to the [Binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution), and we write $\\text{M} \\sim Binomial(n,p)$. The next code implements a Python function `bin(n,p)` that represents the Binomial distribution. Our goal is to plot a histogram. Fill in the remaining pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bernoulli and Binomial distributions were implemented by hand above. We did not have to do this though, since numpy includes its own implementation. So let us check the documentation of [np.random.binomial](https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.binomial.html). It is said that we should use `np.random.binomial` in the following way:\n",
    "```python\n",
    "np.random.binomial(n, p, size)\n",
    "```\n",
    "where the parameters are n for the number of tosses, p for the probability of a positive result (in our case, heads) and size for the output shape. So let us answer the following question. Which is faster? Our homemade `bernoulli()` or numpy's `np.random.binomial()`? We can answer this question with the [time](https://docs.python.org/3/library/time.html) module as follows.\n",
    "\n",
    "```python\n",
    "import time\n",
    "print(\"Our homemade bernoulli():\")\n",
    "start = time.time()\n",
    "toss_coin(100000,0.5)\n",
    "print(\"Proportion of heads: %f\" %toss_coin())\n",
    "end = time.time()\n",
    "print(\"Time taken by our homemade bernoulli(): \", end - start)\n",
    "\n",
    "print(\"Numpy's np.random.binomial():\")\n",
    "start = time.time()\n",
    "pHeads = np.mean(np.random.binomial(1, 0.5, 100000))\n",
    "end = time.time()\n",
    "print(\"Proportion of heads: %f\" %pHeads)\n",
    "print(\"Time taken by Numpy's np.random.binomial(): \", end - start)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our homemade bernoulli():\n",
      "Proportion of heads: 0.505600\n",
      "Time taken by our homemade bernoulli(): 0.274933 s\n",
      "\n",
      "\n",
      "Numpy's np.random.binomial():\n",
      "Proportion of heads: 0.502870\n",
      "Time taken by Numpy's np.random.binomial(): 0.003727 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(\"Our homemade bernoulli():\")\n",
    "start = time.time()\n",
    "toss_coin(100000,0.5)\n",
    "print(\"Proportion of heads: %f\" %toss_coin())\n",
    "end = time.time()\n",
    "print(\"Time taken by our homemade bernoulli(): %f s\" %(end - start))\n",
    "print(\"\\n\")\n",
    "print(\"Numpy's np.random.binomial():\")\n",
    "start = time.time()\n",
    "pHeads = np.mean(np.random.binomial(1, 0.5,100000))\n",
    "end = time.time()\n",
    "print(\"Proportion of heads: %f\" %pHeads)\n",
    "print(\"Time taken by Numpy's np.random.binomial(): %f s\" %(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows why it is good practice to stick with numpy. Not only did we save several lines of code, but we  also had a much better performance (by a factor of nearly 100!). Furthermore by choosing reliable, hardened libraries like numpy it is much less likely that we experiment bugs than with our own homemade code. Of course, the whole purpose of all this is that we code, so we shall implement many things by hand. Just beware that if you want to accomplish something with Python, it is very likely that some people already did it for you. Reuse code!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4. Performance test for the Binomial distribution.\n",
    "\n",
    "Implement a similiar performance test between our homemade `bin()` and numpy's `np.random.binomial()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Normal distribution\n",
    "\n",
    "Th next probability distribution we shall examine is perhaps the most important one: Gauss' Normal. We shall write it the following way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Th n ext probability distribution we"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
